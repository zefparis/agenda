# ü§ñ Configuration OpenAI - GPT-4-Turbo

## üéØ Changements Effectu√©s

### ‚ùå Probl√®me Initial
- Mod√®le utilis√© : `gpt-5` (n'existe pas)
- Param√®tre : `max_completion_tokens` (non support√© par tous les mod√®les)
- R√©sultat : Erreurs, lenteur, r√©ponses vides

### ‚úÖ Solution Appliqu√©e
- Mod√®le : **`gpt-4-turbo-preview`** (stable et rapide)
- Param√®tre : **`max_tokens`** (compatible tous mod√®les)
- Configuration optimis√©e pour parsing + streaming

---

## üìÅ Fichiers Modifi√©s

### 1. `/src/lib/openai/client.ts` - Configuration Principale

**Avant** :
```typescript
export const MODELS = {
  PARSING: 'gpt-5',
  ADVANCED: 'gpt-5',
}
```

**Apr√®s** :
```typescript
export const MODELS = {
  PARSING: 'gpt-4-turbo-preview',   // Pour parsing JSON
  ADVANCED: 'gpt-4-turbo-preview',  // Pour conversations
}

export const COMMON_CONFIG = {
  temperature: 0.7,
  max_tokens: 2000,
}
```

---

### 2. `/src/lib/openai/parser.ts` - Parser de Langage Naturel

**Changements** :
- ‚úÖ `max_completion_tokens` ‚Üí `max_tokens`
- ‚úÖ `temperature: 0.3` pour parsing pr√©cis
- ‚úÖ Logs mis √† jour "GPT-4-Turbo"

**Code** :
```typescript
const completion = await openai.chat.completions.create({
  model: MODELS.PARSING,
  messages: [...],
  max_tokens: 500,          // ‚úÖ
  temperature: 0.3,         // ‚úÖ Faible pour pr√©cision
  response_format: { type: 'json_object' },
});
```

---

### 3. `/src/app/api/chat/route.ts` - Route de Chat avec Streaming

**Changements** :
- ‚úÖ `max_completion_tokens` ‚Üí `max_tokens`
- ‚úÖ Suppression de `stream_options` (non n√©cessaire)
- ‚úÖ Configuration simplifi√©e

**Code** :
```typescript
const response = await openai.chat.completions.create({
  model: MODELS.ADVANCED,
  messages: [...],
  max_tokens: 2000,    // ‚úÖ
  temperature: 0.7,    // ‚úÖ
  stream: true,
});
```

---

### 4. `/src/app/api/test-models/route.ts` - Test des Mod√®les

**Changements** :
- ‚úÖ `max_completion_tokens` ‚Üí `max_tokens`
- ‚úÖ Message de test am√©lior√©
- ‚úÖ Logs mis √† jour

---

### 5. `/src/app/api/test-openai/route.ts` - üÜï Route de Test Compl√®te

**Nouvelle route cr√©√©e** pour tester tous les aspects d'OpenAI :

**Tests inclus** :
1. ‚úÖ Client initialis√©
2. ‚úÖ Configuration des mod√®les
3. ‚úÖ Compl√©tion simple
4. ‚úÖ Parsing JSON structur√©
5. ‚úÖ Streaming
6. ‚úÖ Parsing langage naturel

**Utilisation** :
```bash
curl http://localhost:3000/api/test-openai
```

ou visiter dans le navigateur :
```
http://localhost:3000/api/test-openai
```

---

## üß™ Tests de Validation

### Test 1 : Configuration
```bash
# V√©rifier que la cl√© API est pr√©sente
echo $OPENAI_API_KEY

# Doit commencer par sk-
```

### Test 2 : Test Complet
```bash
curl http://localhost:3000/api/test-openai | jq

# R√©sultat attendu:
{
  "success": true,
  "message": "‚úÖ Tous les tests OpenAI passent avec succ√®s !",
  "summary": {
    "total_tests": 6,
    "passed": 6,
    "failed": 0
  }
}
```

### Test 3 : Chat Simple
```bash
curl -X POST http://localhost:3000/api/chat \
  -H "Content-Type: application/json" \
  -d '{
    "messages": [{"role": "user", "content": "Bonjour"}]
  }'

# Doit streamer la r√©ponse mot par mot
```

### Test 4 : Parsing
```bash
curl -X POST http://localhost:3000/api/parse \
  -H "Content-Type: application/json" \
  -d '{
    "command": "rdv demain √† 14h"
  }' | jq

# R√©sultat attendu:
{
  "success": true,
  "data": {
    "action": "create",
    "type": "event",
    "title": "Rendez-vous",
    "start_date": "2025-11-07T14:00:00.000Z"
  }
}
```

---

## üîß Configuration Requise

### Variables d'Environnement

```env
# .env.local
OPENAI_API_KEY=sk-proj-...     # ‚úÖ REQUIS
OPENAI_ORG_ID=org-...          # ‚ö™ Optionnel
```

### V√©rification
```typescript
// Dans n'importe quelle route API
import { openai, MODELS } from '@/lib/openai/client';

console.log('Client:', openai ? 'OK' : 'NOT INITIALIZED');
console.log('Models:', MODELS);
```

---

## üìä Mod√®les Disponibles

| Mod√®le | Nom Exact | Utilisation | Max Tokens | Co√ªt |
|--------|-----------|-------------|------------|------|
| **GPT-4 Turbo** | `gpt-4-turbo-preview` | Production ‚úÖ | 4096 | ‚Ç¨‚Ç¨‚Ç¨ |
| GPT-4 | `gpt-4` | Legacy | 8192 | ‚Ç¨‚Ç¨‚Ç¨‚Ç¨ |
| GPT-3.5 Turbo | `gpt-3.5-turbo` | Tests/Dev | 4096 | ‚Ç¨ |
| GPT-4o | `gpt-4o` | Plus r√©cent | 4096 | ‚Ç¨‚Ç¨ |

**Choix actuel** : `gpt-4-turbo-preview`
- ‚úÖ Stable et √©prouv√©
- ‚úÖ Support JSON natif
- ‚úÖ Streaming fiable
- ‚úÖ Bon rapport qualit√©/prix

---

## ‚öôÔ∏è Param√®tres Recommand√©s

### Pour Parsing (JSON)
```typescript
{
  model: 'gpt-4-turbo-preview',
  max_tokens: 500,
  temperature: 0.3,              // Faible pour pr√©cision
  response_format: { type: 'json_object' }
}
```

### Pour Chat (Streaming)
```typescript
{
  model: 'gpt-4-turbo-preview',
  max_tokens: 2000,
  temperature: 0.7,              // √âquilibr√©
  stream: true
}
```

### Pour G√©n√©ration Cr√©ative
```typescript
{
  model: 'gpt-4-turbo-preview',
  max_tokens: 1000,
  temperature: 0.9,              // Haute pour cr√©ativit√©
}
```

---

## üö® Erreurs Courantes

### Erreur 1 : "Model does not exist"
```
Error: The model `gpt-5` does not exist
```

**Solution** : Utiliser `gpt-4-turbo-preview` ‚úÖ

---

### Erreur 2 : "Invalid parameter"
```
Error: Unknown parameter: 'max_completion_tokens'
```

**Solution** : Utiliser `max_tokens` au lieu de `max_completion_tokens` ‚úÖ

---

### Erreur 3 : "Authentication failed"
```
Error: Incorrect API key provided
```

**Solutions** :
1. V√©rifier `.env.local` existe
2. V√©rifier `OPENAI_API_KEY=sk-...`
3. Red√©marrer le serveur : `npm run dev`

---

### Erreur 4 : "Rate limit exceeded"
```
Error: Rate limit reached for requests
```

**Solutions** :
- Attendre quelques secondes
- V√©rifier votre plan OpenAI
- Ajouter des retry avec backoff

---

### Erreur 5 : "Timeout"
```
Error: Request timed out
```

**Solutions** :
- Augmenter le timeout dans fetch
- R√©duire `max_tokens`
- V√©rifier connexion r√©seau

---

## üîç Debug

### Activer les Logs D√©taill√©s

```typescript
// Dans n'importe quel fichier
console.log('ü§ñ OpenAI Config:', {
  client: !!openai,
  model: MODELS.ADVANCED,
  env: process.env.OPENAI_API_KEY?.slice(0, 10) + '...'
});
```

### Tester Manuellement

```typescript
// Page de test : /app/test-openai/page.tsx
'use client';
import { useEffect, useState } from 'react';

export default function TestOpenAI() {
  const [result, setResult] = useState(null);
  
  useEffect(() => {
    fetch('/api/test-openai')
      .then(r => r.json())
      .then(setResult);
  }, []);
  
  return <pre>{JSON.stringify(result, null, 2)}</pre>;
}
```

---

## üìà Monitoring

### Logs √† Surveiller

```bash
# Logs serveur
npm run dev

# Chercher dans les logs:
‚úÖ "ü§ñ Parsing with OpenAI GPT-4-Turbo"
‚úÖ "üí¨ Chat request with X messages"
‚úÖ "‚úÖ OpenAI parsed"
‚ùå "‚ùå Error parsing with OpenAI"
```

### M√©triques

- **Taux de succ√®s parsing** : > 95%
- **Temps de r√©ponse** : < 3 secondes
- **Taux d'erreur** : < 1%

---

## üöÄ Migration Checklist

- [x] Remplacer `gpt-5` ‚Üí `gpt-4-turbo-preview`
- [x] Remplacer `max_completion_tokens` ‚Üí `max_tokens`
- [x] Supprimer `stream_options`
- [x] Ajuster `temperature` selon usage
- [x] Cr√©er route de test `/api/test-openai`
- [x] Mettre √† jour logs et commentaires
- [ ] Tester en local
- [ ] Tester en production
- [ ] Monitorer les erreurs

---

## üìö Ressources

- [OpenAI Models](https://platform.openai.com/docs/models)
- [Chat Completion API](https://platform.openai.com/docs/api-reference/chat)
- [Streaming](https://platform.openai.com/docs/api-reference/streaming)
- [Error Codes](https://platform.openai.com/docs/guides/error-codes)

---

## ‚úÖ R√©sum√©

| Aspect | Avant | Apr√®s |
|--------|-------|-------|
| **Mod√®le** | gpt-5 ‚ùå | gpt-4-turbo-preview ‚úÖ |
| **Param√®tre** | max_completion_tokens ‚ùå | max_tokens ‚úÖ |
| **Streaming** | Avec stream_options | Simple stream ‚úÖ |
| **Tests** | Basiques | Complets (6 tests) ‚úÖ |
| **Logs** | Peu clairs | D√©taill√©s ‚úÖ |
| **Stabilit√©** | Erreurs fr√©quentes | Stable ‚úÖ |

---

**Date** : 6 novembre 2025  
**Version** : 2.0.0  
**Status** : ‚úÖ Production Ready
